# Portfolio
# Curious Learner
Exploration in the field of Data science began when I had access to computers since childhood. This opportunity evoked my curiosity to comprehend how computers can perceive, interpret data and provide output. The mechanism behind these languages gave me a vivid idea about how it aids humanity with real-time problems. Keeping up the same hunger and quest for knowledge, I opted for Computer science during undergrad. This wise decision helped me comprehend, design, develop and deploy applications that make society grow along with technology as their best companion. In today's technological advancements, high-performance computing and data visualization have always fascinated me, and I continue to be an active learner and seeker throughout my journey. This expedition is a substantial reason to pursue for a Master's degree in Data Science.

# Technical Skills

- **Programming Languages**: Python, JavaScript, SQL, R, Java

- **Python Libraries**: Pandas, NumPy, Matplotlib, Seaborn, XGBoost, OpenCV, TensorFlow, HuggingFace

- **ML Algorithms**: Linear Regression, Random Forest, Decision Tree, k-means clustering, SVM, Naive Bayes, Neural Networks

_ **Data Mining Techniques**: TF-IDF, Word2Vec, feature extraction, clustering algorithms

- **Frameworks**: React, Node.js, Express, Flask, Fast API

- **Database & Big Datas**: MySQL, PostgreSQL, MongoDB, Apache Spark, AirFlow, Neo4j, Databricks, Docker

- **Cloud**: AWS

- **Tools**: Git, GitHub, VS Code, PyCharm, Eclipse, Jupyter Notebook, Postman, Heroku, Docker


# Education
- M.S., Data Science | Indiana University Bloomington (August 2023 - May 2025), GPA: 3.5/4											       		
- B.TECH., Computer Science | St. Joseph's College of Engineering (August 2019 - May 2023), GPA: 8.68/10

## Relevant Coursework
Statistics, Applied Algorithms, Database Concepts, Machine Learning in Econ, Data Mining, Big Data, Natural Language Processing, Data Visualization, Cloud Computing, Operating Systems, Distributed Systems, Computer Architecture, Software Engineering

# Work Experience
### **Graduate Research Assistantship @ Community AI for Education - Indiana University Indianapolis  (_November 2024 - present_)**
- Developed an automated system to gather and process information from online sources, significantly reducing manual effort and improving data collection speed.
- uilt a pipeline to break down and analyze text efficiently, allowing for quick extraction of key insights from large documents.
- Integrated AI models to summarize PDFs, extract important details, and improve searchability, making information retrieval faster and more effective.

### **Software Engineer Internship @ FoodFight.Inc (_June 2024 - Aug 2024_)**
- Built high-performance RESTful APIs using FastAPI, improving response times by 15% and reducing errors by 10% through robust data validation.
- Optimized database operations with SQLAlchemy, cutting query execution time and boosting efficiency, leading to a 10% reduction in errors.
- Developed a personalized user-matching system using similarity metrics, analyzing behavior and preferences to enhance recommendation accuracy.
- Implemented AWS Lambda for serverless processing, reducing idle server costs by 20% and enabling real-time monitoring with AWS CloudWatch.

### **Software Engineer Internship @ Indiespirit Technologies (_August 2021 - November 2021_)**
- Led the successful implementation of React JS concepts and functionalities, such as components, forms, events, keys, routers, and animations, resulting in a seamless user interface and a 40% acceleration in overall website performance.
- Tested React Apps using React Testing Library, Jest Library and Snapshot Testing. Utilized Git for version controlling and regularly pushed the code to GitHub.

### **Data Science Internship @ MaDeIT Innovation Foundation - Indian Institute of Information Technology, Design and Manufacturing  (_August 2021 - September 2021_)**
- Developed a novel model to predict insurance claim probabilities with 85% accuracy, potentially streamlining claims processing and reducing manual inspection costs by 30%, as estimated through internal testing.
- Leveraged transfer learning with YOLOv5 to detect and classify vehicle damage with 95% mean average precision (mAP), significantly outperforming traditional object detection methods.
- Utilized Roboflow datasets to manage over 10,000 labeled images, optimizing data preparation and augmentation, ultimately reducing model training time by 25%.


# Projects
### **[LLM based Web Crawler](https://github.com/KirthivasanPN-hash/Data_engineering/tree/main/AI_web_crawler) | Python, Crawl4AI, OpenAI (_January 2025 - February 2025_)**
- Strategically wrote a web scraping program using Crawl4AI and Python, leveraging advanced browser control and LLM-based extraction to parse and extract structured data, enabling efficient and reusable data ingestion.
- Processed data processing workflows using Pydantic for schema validation and CSV serialization, automating data storage for structured analysis, and improving data accessibility for Research Assistantship projects.

### **[Washington Housing Sales Dashboard](https://public.tableau.com/views/WashingtonHousingPrices/Washington_Housing_Prices?:language=en-US&:sid=&:redirect=auth&:display_count=n&:origin=viz_share_link) | Tableau (_December 2024 - January 2025_)**
- Designed and coded a robust ELT pipeline using Docker containers, automating the extraction, transformation, and loading of large-scale movie dataset. Performed Orchestration via Airflow for optimizing task scheduling and error handling.
- Integrated DBT for data transformation, utilizing Jinja templates and macros to create SQL models for filtering the movie dataset. Executed transformations, complex aggregations, joins, and data enrichment techniques, to ensure optimization.
- Configured a cron job for automated pipeline execution, streamline the entire workflow, minimizing manual intervention, reducing errors, and operational efficiency by maintaining regular updates and data processing intervals.

### **[Automated Movie Data Transformation Pipeline](https://github.com/KirthivasanPN-hash/Data_engineering) | Python, SQL, Docker, DBT, CRON JOB, Airflow (_December 2024 - January 2025_)**
- Designed and coded a robust ELT pipeline using Docker containers, automating the extraction, transformation, and loading of large-scale movie dataset. Performed Orchestration via Airflow for optimizing task scheduling and error handling.
- Integrated DBT for data transformation, utilizing Jinja templates and macros to create SQL models for filtering the movie dataset. Executed transformations, complex aggregations, joins, and data enrichment techniques, to ensure optimization.
- Configured a cron job for automated pipeline execution, streamline the entire workflow, minimizing manual intervention, reducing errors, and operational efficiency by maintaining regular updates and data processing intervals.

### **[Market Pulse: Real-Time Stock Data Pipeline](https://github.com/KirthivasanPN-hash/Data_engineering) | Python, AWS (EC2, RDS, Athena, Glue, S3) BOTO 3, Kafka (_January 2024 - February 2024_)**
- Initiated AWS EC2 to manage Kafka brokers and producer/consumer communications, enabling real-time data streaming services. Configured Zookeeper for efficient cluster coordination and fault-tolerant operations.
- Implemented Boto3 SDK to interact with AWS services via Python, facilitating real-time data ingestion from Kafka into S3 buckets while ensuring swift preparation for cataloging in RDS via AWS Glue.
- Set up a real-time stock price pipeline and AWS Glue crawlers to load and structure data in Athena, enabling real-time stock market analysis through SQL queries and insights generation.
  
### **[Aviation Analytics Pipeline on GCP](https://github.com/KirthivasanPN-hash/Data_engineering/tree/main/Flight_ticket_ETL) | GCP (VPC, Airflow, DAG, Big query, Looker) (_August 2024 - September 2024_)**
- Led the development of an ETL pipeline using Google Cloud Platform, streamlining data processes and increasing efficiency by 25%. Utilized Cloud Storage for data warehousing, and workflow orchestration, resulting in a scalable data infrastructure.
- Architected a secure Virtual Private Cloud (VPC) for cluster deployment, optimizing large-scale aviation data processing, Cloud IAM for granular access control, and data handling efficiency by 30%.

### **[Deliverwise - delivery service application](https://github.com/rohit2905/CSCI_P565_Team4_Backend) | MERN Stack, Paypal SDK (_January 2024 - May 2024_)**
- Developed a sophisticated React.js recommendation system in an advanced web development course, boosting user engagement by 40%. Implemented robust authentication protocols for enhanced security, data-driven design, and application security.
- Engineered RESTful APIs for backend operations like management, tracking, chatting, and reviews; implemented strong error handling measures and client-centric error messages, ensuring operational continuity and client engagement.

### **[Schmooze - Chatting Cord](https://github.com/KirthivasanPN-hash/Schmooze-ChattingCord) | React.js, RESTful API, Postman, Socket IO (_October 2021 - December 2021_)**
- Engineered an interactive web application with real-time chat functionality, leveraging HTML, CSS, and React JS.
- Created Website components an props, event handlers, and Hooks to optimize the user interface, resulting in a 40% increase
in user engagement and a 25% decrease in bounce rate.
- Integrated Express JS to create a server for Socket.IO to emit and output events performed by a user in specific groups to the
DOM and deployed using the Heroku platform
